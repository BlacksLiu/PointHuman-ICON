{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "from PIL import Image\n",
    "import torch \n",
    "import os \n",
    "\n",
    "# pytorch3d pipeline:render normal from ground truth mesh\n",
    "from lib.common.render import Render, cleanShader\n",
    "from lib.evaluator.evaluator_util import *\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "from pytorch3d.renderer import (\n",
    "    FoVOrthographicCameras,\n",
    "    RasterizationSettings,\n",
    "    MeshRasterizer,\n",
    "    BlendParams,\n",
    "    MeshRenderer,\n",
    "    look_at_view_transform,\n",
    "    OrthographicCameras,\n",
    "    PointsRasterizationSettings,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizer,\n",
    "    AlphaCompositor,\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_camera(scale, device):\n",
    "    R, T = look_at_view_transform(20, 0, 0)\n",
    "\n",
    "    camera = FoVOrthographicCameras(\n",
    "        device=device,\n",
    "        R=R,\n",
    "        T=T,\n",
    "        znear=100.0,\n",
    "        zfar=-100.0,\n",
    "        max_y=100.0,\n",
    "        min_y=-100.0,\n",
    "        max_x=100.0,\n",
    "        min_x=-100.0,\n",
    "        scale_xyz=(scale * np.ones(3), ),\n",
    "    )\n",
    "\n",
    "    return camera\n",
    "\n",
    "def init_renderer(cam, device):\n",
    "    raster_settings_mesh = RasterizationSettings(\n",
    "                image_size=512,\n",
    "                blur_radius=np.log(1.0 / 1e-4) * 1e-7,\n",
    "                faces_per_pixel=30,\n",
    "            )\n",
    "    meshRas = MeshRasterizer(cameras=cam, raster_settings=raster_settings_mesh)\n",
    "    blendparam = BlendParams(1e-4, 1e-4, (0.0, 0.0, 0.0))\n",
    "    renderer = MeshRenderer(\n",
    "            rasterizer=meshRas,\n",
    "            shader=cleanShader(device=device, cameras=cam, blend_params=blendparam),\n",
    "        )\n",
    "    return renderer\n",
    "\n",
    "def project_mesh(render, mesh, calib=None, scale=100.0):\n",
    "    if calib is not None:\n",
    "        verts_gt = torch.as_tensor(mesh.vertices * scale).float()\n",
    "        proj_verts = projection(verts_gt, calib)\n",
    "        proj_verts[:, 1] *= -1\n",
    "    else:\n",
    "        proj_verts = torch.as_tensor(mesh.vertices).float()\n",
    "    faces_gt = torch.as_tensor(mesh.faces).long()\n",
    "\n",
    "    proj_mesh = render.VF2Mesh(proj_verts, faces_gt)\n",
    "    return proj_mesh\n",
    "\n",
    "def get_normal_img(renderer, mesh):\n",
    "    rendered_img = (\n",
    "        renderer(mesh[0])[0:1, :, :, :3] - 0.5\n",
    "    ) * 2.0\n",
    "    rendered_img = ((rendered_img + 1.0) * 0.5)[0]\n",
    "    return rendered_img\n",
    "\n",
    "\n",
    "def get_pifuhd_calib(calib_path):\n",
    "    # loading calibration data\n",
    "    param = np.load(calib_path, allow_pickle=True)\n",
    "    # pixel unit / world unit is equal to 1\n",
    "    # pixel unit / uv unit ---> is ortho_ratio\n",
    "    ortho_ratio = param.item().get('ortho_ratio')\n",
    "    # world unit / model unit\n",
    "    scale = param.item().get('scale')\n",
    "\n",
    "    # camera center world coordinate\n",
    "    center = param.item().get('center')\n",
    "    # model rotation\n",
    "    R = param.item().get('R')\n",
    "    #translate the position of camera into world coordinate origin. \n",
    "    translate = -np.matmul(R, center).reshape(3, 1)\n",
    "    extrinsic = np.concatenate([R, translate], axis=1)\n",
    "    extrinsic = np.concatenate([extrinsic, np.array([0, 0, 0, 1]).reshape(1, 4)], 0)\n",
    "\n",
    "    # Match camera space to image pixel space\n",
    "    scale_intrinsic = np.identity(4)\n",
    "    scale_intrinsic[0, 0] = scale / ortho_ratio\n",
    "    #render code, this part flip(axis =0),therefore, y need change\n",
    "    scale_intrinsic[1, 1] = -scale / ortho_ratio\n",
    "    scale_intrinsic[2, 2] = scale / ortho_ratio\n",
    "\n",
    "\n",
    "    #uv space is [-1,1] we map [-256,255]->[-1,1]\n",
    "    # Match image pixel space to image uv space\n",
    "    uv_intrinsic = np.identity(4)\n",
    "    uv_intrinsic[0, 0] = 1.0 / float(512 // 2)\n",
    "    uv_intrinsic[1, 1] = 1.0 / float(512 // 2)\n",
    "    uv_intrinsic[2, 2] = 1.0 / float(512 // 2)\n",
    "\n",
    "    # Transform under image pixel space\n",
    "    trans_intrinsic = np.identity(4)\n",
    "\n",
    "    intrinsic = np.matmul(trans_intrinsic, np.matmul(uv_intrinsic, scale_intrinsic))\n",
    "    calib = np.matmul(intrinsic, extrinsic)\n",
    "    \n",
    "    calib[:3,:3] /= scale\n",
    "    return calib, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transhuman': {'psnr': 27.672826673628308, 'ssim': 0.9486113370316152, 'lpips_vgg': 0.08003283769656451}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "path = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results/transhuman/RENDER_thuman2_transhuman.npy\"\n",
    "dat = np.load(path, allow_pickle=True)\n",
    "\n",
    "score = dat.tolist()\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(score)\n",
    "tmp_dict = {}\n",
    "\n",
    "tmp_dict['transhuman'] = {\n",
    "\t'psnr': df['psnr'].mean(),\n",
    "\t'ssim': df['ssim'].mean(),\n",
    "\t'lpips_vgg': df['lpips_vgg'].mean(),\n",
    "}\n",
    "print(tmp_dict)\n",
    "\n",
    "import json\n",
    "with open(path.replace(\".npy\", '.json'), 'w') as fp:\n",
    "\tfp.write(json.dumps(tmp_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pifuhd metrices calc\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mesh_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/scans\"\n",
    "subject_names = sorted([i.split('.')[0] for i in os.listdir(mesh_dir)])\n",
    "views = [\n",
    "    '000', '120', '240'\n",
    "]\n",
    "icon_calib_dir =  \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape_3views/\"\n",
    "calib_dir =  \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/pifuhd_gen_512\"\n",
    "output_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "pred_mesh_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "\n",
    "# mesh normal rendering\n",
    "scale = 100.0\n",
    "camera = get_camera(scale, device)\n",
    "icon_renderer = init_renderer(camera, device)\n",
    "render = Render(size=512, device=device)\n",
    "\n",
    "radius = 0.005\n",
    "calc_mesh_dist = True\n",
    "calc_NC = True\n",
    "output_normal_map = True\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "method = \"open-pifuhd\"\n",
    "\n",
    "# import trimesh\n",
    "\n",
    "score = []\n",
    "for subject_name in tqdm(subject_names):\n",
    "    mesh_path = os.path.join(mesh_dir, subject_name, f\"{subject_name}.obj\")\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "    for view in views:\n",
    "        # calib_path = os.path.join(calib_dir, subject_name, \"PARAM\", subject_name, f'{int(view)}_0_00.npy')\n",
    "        # calib, scale = get_pifuhd_calib(calib_path)\n",
    "\n",
    "        calib_path = os.path.join(icon_calib_dir, subject_name, \"calib\", f'{view}.txt')\n",
    "        calib = load_calib(calib_path)\n",
    "        if calc_NC:\n",
    "            # to ndc \n",
    "            gt_mesh = project_mesh(render, mesh, calib, scale)\n",
    "            gt_normal_imgs = get_normal_img(icon_renderer, gt_mesh)\n",
    "        \n",
    "        if calc_mesh_dist:\n",
    "            gt_pcl, gt_vertices, gt_faces = get_proj_pcls(mesh_path, calib)\n",
    "            # trimesh.Trimesh(gt_pcl).export('gt_proj.obj')\n",
    "\n",
    "        tmp_dict = {}\n",
    "        tmp_dict['subject_name'] = subject_name\n",
    "        tmp_dict['view'] = view\n",
    "        pred_mesh_path = os.path.join(pred_mesh_dir, method, f'cape/{subject_name}/est_mesh_{view}.obj')\n",
    "        if calc_NC:\n",
    "            pred_mesh = trimesh.load(pred_mesh_path)\n",
    "            pred_mesh = project_mesh(render, pred_mesh, calib=None)\n",
    "            pred_normal_imgs = get_normal_img(icon_renderer, pred_mesh)\n",
    "            normal_img_output = os.path.join(pred_mesh_dir, method, f'normal_map_from_mesh/{view}')\n",
    "            \n",
    "            error = (((pred_normal_imgs - gt_normal_imgs)**2).sum(dim=2).mean())\n",
    "            tmp_dict[f'{method}_nc']=error.cpu().numpy()\n",
    "\n",
    "            if output_normal_map:\n",
    "                if not os.path.exists(normal_img_output):\n",
    "                    os.makedirs(normal_img_output)\n",
    "                \n",
    "                Image.fromarray(\n",
    "                    (\n",
    "                        torch.cat([pred_normal_imgs, gt_normal_imgs], dim=1).cpu().numpy() * 255.0\n",
    "                    ).astype(np.uint8)\n",
    "                ).save(os.path.join(normal_img_output, f'{subject_name}.jpg'))\n",
    "        if calc_mesh_dist:\n",
    "            pred_pcl, vertices, faces = get_proj_pcls(pred_mesh_path)\n",
    "            # trimesh.Trimesh(pred_pcl).export('pred_proj.obj')\n",
    "\n",
    "            if calc_mesh_dist :\n",
    "                chamfer_dist = get_chamfer_distance(gt_pcl, pred_pcl).cpu().numpy()\n",
    "                p2s_dist = get_p2s_distance(gt_vertices, gt_faces, pred_pcl).cpu().numpy()\n",
    "                tmp_dict[f'{method}_chamfer'] = chamfer_dist\n",
    "                tmp_dict[f'{method}_p2s'] = p2s_dist\n",
    "        score.append(tmp_dict)\n",
    "        # break\n",
    "    # break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_path = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/test150.txt\"\n",
    "\n",
    "data = []\n",
    "with open(split_path, 'r', encoding='utf-8') as f:\n",
    "    for ann in f.readlines():\n",
    "        ann = ann.strip('\\n')       #去除文本中的换行符\n",
    "        ann = ann.split('/')[1]\n",
    "        data.append(ann)\n",
    "simple_subject_name = data[:50]\n",
    "hard_subject_name = data[50:]\n",
    "\n",
    "import pandas as pd \n",
    "# df = pd.DataFrame(score)\n",
    "df = pd.DataFrame(score1)\n",
    "\n",
    "easy_df = df.loc[df['subject_name'].isin(simple_subject_name)]\n",
    "hard_df = df.loc[df['subject_name'].isin(hard_subject_name)]\n",
    "\n",
    "print(f\"easy objs num:{len(easy_df)}, hard objs num:{len(hard_df)}\")\n",
    "\n",
    "tmp_dict = {\n",
    "\n",
    "}\n",
    "calc_mesh_dist = True\n",
    "if calc_mesh_dist and calc_NC:\n",
    "    tmp_dict[method] = {\n",
    "        'nc_easy': easy_df[f'{method}_nc'].mean(),\n",
    "        'nc_hard': hard_df[f'{method}_nc'].mean(),\n",
    "        'chamfer_easy': easy_df[f'{method}_chamfer'].mean(),\n",
    "        'chamfer_hard': hard_df[f'{method}_chamfer'].mean(),\n",
    "        'p2s_easy': easy_df[f'{method}_p2s'].mean(),\n",
    "        'p2s_hard': hard_df[f'{method}_p2s'].mean(),\n",
    "    }\n",
    "elif calc_NC:\n",
    "    tmp_dict[method] = {\n",
    "        'nc_easy': easy_df[f'{method}_nc'].mean(),\n",
    "        'nc_hard': hard_df[f'{method}_nc'].mean(),\n",
    "    }\n",
    "else: \n",
    "    tmp_dict[method] = {\n",
    "        'chamfer_easy': easy_df[f'{method}_chamfer'].mean(),\n",
    "        'chamfer_hard': hard_df[f'{method}_chamfer'].mean(),\n",
    "        'p2s_easy': easy_df[f'{method}_p2s'].mean(),\n",
    "        'p2s_hard': hard_df[f'{method}_p2s'].mean(),\n",
    "    }\n",
    "tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = [\n",
    "    f'{i:03d}' for i in range(0,360,10)\n",
    "]\n",
    "view2obj = {\n",
    "    '000': 'est_mesh_0.obj',\n",
    "    '120': 'est_mesh_120.obj',\n",
    "    '240': 'est_mesh_240.obj',\n",
    "}\n",
    "\n",
    "\n",
    "for view in views:\n",
    "    view2obj[view] = f'est_mesh_{int(view)}'\n",
    "view2obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ours (radius=0.005) others render from mesh\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = 'thuman2'\n",
    "# cape \n",
    "if dataset == 'cape':\n",
    "    mesh_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/scans\"\n",
    "    subject_names = sorted([i.split('.')[0] for i in os.listdir(mesh_dir)])\n",
    "    views = [\n",
    "        '000', '120', '240'\n",
    "    ]\n",
    "    calib_dir =  \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape_3views/\"\n",
    "    output_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "    pred_mesh_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "elif dataset == 'thuman2':\n",
    "    mesh_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/thuman2/scans\"\n",
    "    subject_names = sorted([i.split('.')[0] for i in os.listdir(mesh_dir)])\n",
    "    views = [\n",
    "        f'{i:03d}' for i in range(0,360,10)\n",
    "    ]\n",
    "    calib_dir =  \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/thuman2_36views/\"\n",
    "    output_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "    pred_mesh_dir = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "\n",
    "\n",
    "compare_methods = [\n",
    "    'icon-filter',\n",
    "    'icon-nofilter',\n",
    "    'pamir',\n",
    "    'pifu',\n",
    "    # 'pointhuman_1_outputs',\n",
    "    'econ'\n",
    "]\n",
    "\n",
    "view2obj = {\n",
    "    '000': 'est_mesh_0.obj',\n",
    "    '120': 'est_mesh_120.obj',\n",
    "    '240': 'est_mesh_240.obj',\n",
    "}\n",
    "\n",
    "# mesh normal rendering\n",
    "scale = 100.0\n",
    "camera = get_camera(scale, device)\n",
    "icon_renderer = init_renderer(camera, device)\n",
    "render = Render(size=512, device=device)\n",
    "\n",
    "radius = 0.005\n",
    "calc_mesh_dist = True\n",
    "calc_NC = True\n",
    "output_normal_map = True\n",
    "\n",
    "def init_point_renderer(radius, device):\n",
    "    R, T = look_at_view_transform(20, 0, 0)\n",
    "    cameras = OrthographicCameras(device=device, R=R, T=T)\n",
    "    raster_settings = PointsRasterizationSettings(\n",
    "        image_size=512, \n",
    "        radius = radius,\n",
    "        points_per_pixel = 10\n",
    "    )\n",
    "\n",
    "    point_rasterizer = PointsRasterizer(cameras=cameras, raster_settings=raster_settings)\n",
    "    point_renderer = PointsRenderer(\n",
    "        rasterizer=point_rasterizer,\n",
    "        compositor=AlphaCompositor(background_color=(0, 0, 0))\n",
    "    )\n",
    "\n",
    "    return point_renderer\n",
    "\n",
    "# point cloud renderer \n",
    "pcls_renderer = init_point_renderer(radius, device)\n",
    "\n",
    "score = []\n",
    "from tqdm import tqdm\n",
    "for subject_name in tqdm(subject_names):\n",
    "    mesh_path = os.path.join(mesh_dir, subject_name, f\"{subject_name}.obj\")\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "    for view in views:\n",
    "        calib_path = os.path.join(calib_dir, subject_name, \"calib\", f'{view}.txt')\n",
    "        calib = load_calib(calib_path)\n",
    "        if calc_NC:\n",
    "            # to ndc \n",
    "            gt_mesh = project_mesh(render, mesh, calib, scale)\n",
    "            gt_normal_imgs = get_normal_img(icon_renderer, gt_mesh)\n",
    "\n",
    "        # for chamfer and p2s\n",
    "        if calc_mesh_dist:\n",
    "            gt_pcl, gt_vertices, gt_faces = get_proj_pcls(mesh_path, calib)\n",
    "\n",
    "        normal_imgs = [gt_normal_imgs]\n",
    "        tmp_dict = {}\n",
    "        tmp_dict['subject_name'] = subject_name\n",
    "        tmp_dict['view'] = view\n",
    "        for method in compare_methods:\n",
    "            if 'pointhuman' not in method:\n",
    "                # render normal from pointclouds\n",
    "\n",
    "                # pred_mesh_path = os.path.join(pred_mesh_dir, method, f'cape/{subject_name}/{view2obj[view]}')\n",
    "                # pred_pcl, _, _ = get_proj_pcls(pred_mesh_path)\n",
    "                # pred_normal_imgs = get_pcls_normal_map(pcls_renderer, pred_pcl)\n",
    "\n",
    "                # render normal from mesh \n",
    "                pred_mesh_path = os.path.join(pred_mesh_dir, method, f'cape/{subject_name}/{view2obj[view]}')\n",
    "                if 'econ' in method:\n",
    "                    pred_mesh_path = os.path.join(pred_mesh_dir, method, f'cape/{subject_name}/cape-{subject_name}-{int(view):03d}_final.obj')\n",
    "                \n",
    "                if calc_NC:\n",
    "                    pred_mesh = trimesh.load(pred_mesh_path)\n",
    "                    pred_mesh = project_mesh(render, pred_mesh, calib=None)\n",
    "                    pred_normal_imgs = get_normal_img(icon_renderer, pred_mesh)\n",
    "                    normal_img_output = os.path.join(pred_mesh_dir, method, f'normal_map_from_mesh/{view}')\n",
    "                \n",
    "                if calc_mesh_dist:\n",
    "                    pred_pcl, _, _ = get_proj_pcls(pred_mesh_path)\n",
    "                    trimesh.Trimesh(gt_pcl).export(f'{method}_pred_proj.obj')\n",
    "            else:\n",
    "                pred_mesh_path = os.path.join(pred_mesh_dir, method, f'cape/{subject_name}/{view}/est_scan.obj')\n",
    "                \n",
    "                pred_pcl, _, _ = get_ori_pcls(pred_mesh_path, calib_path, z_norm=False)\n",
    "                pred_normal_imgs = get_pcls_normal_map(pcls_renderer, pred_pcl)\n",
    "                normal_img_output = os.path.join(pred_mesh_dir, method, f'normal_map_{radius}/{view}')\n",
    "            if calc_NC:\n",
    "                error = (((pred_normal_imgs - gt_normal_imgs)**2).sum(dim=2).mean())\n",
    "                tmp_dict[f'{method}_nc']=error.cpu().numpy()\n",
    "            \n",
    "            if output_normal_map:\n",
    "                if not os.path.exists(normal_img_output):\n",
    "                    os.makedirs(normal_img_output)\n",
    "                Image.fromarray(\n",
    "                    (\n",
    "                        pred_normal_imgs.cpu().numpy() * 255.0\n",
    "                    ).astype(np.uint8)\n",
    "                ).save(os.path.join(normal_img_output, f'{subject_name}.jpg'))\n",
    "            if calc_mesh_dist :\n",
    "                chamfer_dist = get_chamfer_distance(gt_pcl, pred_pcl).cpu().numpy()\n",
    "                p2s_dist = get_p2s_distance(gt_vertices, gt_faces, pred_pcl).cpu().numpy()\n",
    "                tmp_dict[f'{method}_chamfer'] = chamfer_dist\n",
    "                tmp_dict[f'{method}_p2s'] = p2s_dist\n",
    "        score.append(tmp_dict)\n",
    "        break\n",
    "    break\n",
    "    \n",
    "# output_root = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "\n",
    "# npy_path = os.path.join(output_root, f'econ_cape_NC_{radius}_mesh.npy')\n",
    "# np.save(npy_path, score, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_path = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/test150.txt\"\n",
    "\n",
    "data = []\n",
    "with open(split_path, 'r', encoding='utf-8') as f:\n",
    "    for ann in f.readlines():\n",
    "        ann = ann.strip('\\n')       #去除文本中的换行符\n",
    "        ann = ann.split('/')[1]\n",
    "        data.append(ann)\n",
    "simple_subject_name = data[:50]\n",
    "hard_subject_name = data[50:]\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(score)\n",
    "\n",
    "easy_df = df.loc[df['subject_name'].isin(simple_subject_name)]\n",
    "hard_df = df.loc[df['subject_name'].isin(hard_subject_name)]\n",
    "\n",
    "print(f\"easy objs num:{len(easy_df)}, hard objs num:{len(hard_df)}\")\n",
    "\n",
    "tmp_dict = {\n",
    "\n",
    "}\n",
    "calc_mesh_dist = True\n",
    "for method in compare_methods:\n",
    "    if calc_mesh_dist and calc_NC:\n",
    "        tmp_dict[method] = {\n",
    "            'nc_easy': easy_df[f'{method}_nc'].mean(),\n",
    "            'nc_hard': hard_df[f'{method}_nc'].mean(),\n",
    "            'chamfer_easy': easy_df[f'{method}_chamfer'].mean(),\n",
    "            'chamfer_hard': hard_df[f'{method}_chamfer'].mean(),\n",
    "            'p2s_easy': easy_df[f'{method}_p2s'].mean(),\n",
    "            'p2s_hard': hard_df[f'{method}_p2s'].mean(),\n",
    "        }\n",
    "    elif calc_NC:\n",
    "        tmp_dict[method] = {\n",
    "            'nc_easy': easy_df[f'{method}_nc'].mean(),\n",
    "            'nc_hard': hard_df[f'{method}_nc'].mean(),\n",
    "        }\n",
    "    else: \n",
    "        tmp_dict[method] = {\n",
    "            'chamfer_easy': easy_df[f'{method}_chamfer'].mean(),\n",
    "            'chamfer_hard': hard_df[f'{method}_chamfer'].mean(),\n",
    "            'p2s_easy': easy_df[f'{method}_p2s'].mean(),\n",
    "            'p2s_hard': hard_df[f'{method}_p2s'].mean(),\n",
    "        }\n",
    "tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "compare_methods = [\n",
    "    'icon-filter',\n",
    "    'icon-nofilter',\n",
    "    'pamir',\n",
    "    'pifu',\n",
    "    # 'pointhuman_1_outputs'\n",
    "]\n",
    "\n",
    "output_root = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results\"\n",
    "radius=0.005\n",
    "npy_path = os.path.join(output_root, f'cape_NC_no_pretrain_{radius}_mesh.npy')\n",
    "# np.save(npy_path, score, allow_pickle=True)\n",
    "score = list(np.load(npy_path, allow_pickle=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_path = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/test150.txt\"\n",
    "\n",
    "data = []\n",
    "with open(split_path, 'r', encoding='utf-8') as f:\n",
    "    for ann in f.readlines():\n",
    "        ann = ann.strip('\\n')       #去除文本中的换行符\n",
    "        ann = ann.split('/')[1]\n",
    "        data.append(ann)\n",
    "simple_subject_name = data[:50]\n",
    "hard_subject_name = data[50:]\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(score)\n",
    "easy_df = df.loc[df['subject_name'].isin(simple_subject_name)]\n",
    "hard_df = df.loc[df['subject_name'].isin(hard_subject_name)]\n",
    "\n",
    "print(f\"easy objs num:{len(easy_df)}, hard objs num:{len(hard_df)}\")\n",
    "\n",
    "tmp_dict = {\n",
    "\n",
    "}\n",
    "calc_mesh_dist = True\n",
    "for method in compare_methods:\n",
    "    if calc_mesh_dist:\n",
    "        tmp_dict[method] = {\n",
    "            'nc_easy': easy_df[f'{method}_nc'].mean(),\n",
    "            'nc_hard': hard_df[f'{method}_nc'].mean(),\n",
    "            'chamfer_easy': easy_df[f'{method}_chamfer'].mean(),\n",
    "            'chamfer_hard': hard_df[f'{method}_chamfer'].mean(),\n",
    "            'p2s_easy': easy_df[f'{method}_p2s'].mean(),\n",
    "            'p2s_hard': hard_df[f'{method}_p2s'].mean(),\n",
    "        }\n",
    "    else: \n",
    "        tmp_dict[method] = {\n",
    "            'chamfer_easy': easy_df[f'{method}_chamfer'].mean(),\n",
    "            'chamfer_hard': hard_df[f'{method}_chamfer'].mean(),\n",
    "            'p2s_easy': easy_df[f'{method}_p2s'].mean(),\n",
    "            'p2s_hard': hard_df[f'{method}_p2s'].mean(),\n",
    "        }\n",
    "\n",
    "tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test gt mesh projection \n",
    "\n",
    "mesh_path = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/data/cape/scans/00032-longshort-flying_eagle-000240/00032-longshort-flying_eagle-000240.obj\"\n",
    "calib_path = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/mnt/local4T/pengfei/projects/PointHuman/PointHuman-ICON/results/econ/MESH_thuman2_econ.npy\"\n",
    "import numpy as np \n",
    "dat = np.load(path, allow_pickle=True)\n",
    "len(dat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointhuman-torch1.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
